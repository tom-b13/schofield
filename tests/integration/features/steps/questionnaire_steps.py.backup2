"""Step definitions for questionnaire_integration.feature using an in-memory SUT.

Implements a lightweight mock Questionnaire Service with endpoints:
- GET /response-sets/{rs_id}/screens/{screen_id}
- PATCH /response-sets/{rs_id}/answers/{question_id}
- POST /response-sets/{rs_id}/regenerate-check
- POST /questionnaires/import (CSV in multipart)
- GET /questionnaires/{id}
- GET /questionnaires/{id}/export

Validates responses against provided JSON Schemas where applicable.
"""

from __future__ import annotations

import csv
import io
import json
import os
import uuid
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

from behave import given, when, then

# Lightweight import self-check marker to distinguish import failures
STEP_MODULE_IMPORTED = True
print("DEBUG questionnaire_integration_steps: imported")

# Guard jsonschema imports to avoid hard import-time failures
try:
    from jsonschema import FormatChecker, Draft202012Validator, RefResolver  # type: ignore
    _JSONSCHEMA_IMPORT_ERROR = None
except ImportError as _e:  # pragma: no cover - surfaced during step execution if used
    FormatChecker = Draft202012Validator = RefResolver = None  # type: ignore
    _JSONSCHEMA_IMPORT_ERROR = _e


# -----------------------------
# In-memory mock service (SUT)
# -----------------------------


def _gen_uuid() -> str:
    return str(uuid.uuid4())


@dataclass
class Question:
    question_id: str
    screen_id: str
    external_qid: str
    question_text: str
    answer_kind: str
    mandatory: bool
    question_order: int


@dataclass
class Screen:
    screen_id: str
    questionnaire_id: str
    screen_key: str
    title: str
    order: int


@dataclass
class Questionnaire:
    questionnaire_id: str
    key: str
    title: str


@dataclass
class AnswerRow:
    response_set_id: str
    question_id: str
    value: Any


@dataclass
class AnswerOption:
    question_id: str
    value: str
    label: str
    sort_index: int


class MockQuestionnaireService:
    def __init__(self) -> None:
        self.reset()

    def reset(self) -> None:
        self.questionnaires: Dict[str, Questionnaire] = {}
        self.screens: Dict[str, Screen] = {}
        self.questions: Dict[str, Question] = {}
        self.questions_by_external: Dict[str, str] = {}
        self.answers: List[AnswerRow] = []
        self.answer_options: List[AnswerOption] = []
        self.response_sets: Dict[str, Dict[str, Any]] = {}
        # response_set state: {"version": int, "idempotency": {(qid, key): value}}

    # ----------------------
    # Setup / data mutation
    # ----------------------
    def create_questionnaire(self, questionnaire_id: str, key: str, title: str) -> None:
        self.questionnaires[questionnaire_id] = Questionnaire(questionnaire_id, key, title)

    def create_screen(
        self, screen_id: str, questionnaire_id: str, screen_key: str, title: str, order: int
    ) -> None:
        self.screens[screen_id] = Screen(screen_id, questionnaire_id, screen_key, title, order)

    def create_question(
        self,
        question_id: str,
        screen_id: str,
        external_qid: str,
        question_text: str,
        answer_kind: str,
        mandatory: bool,
        question_order: int,
    ) -> None:
        q = Question(
            question_id=question_id,
            screen_id=screen_id,
            external_qid=external_qid,
            question_text=question_text,
            answer_kind=answer_kind,
            mandatory=mandatory,
            question_order=question_order,
        )
        self.questions[question_id] = q
        self.questions_by_external[external_qid] = question_id

    def ensure_response_set(self, response_set_id: str, company_id: str) -> None:
        self.response_sets.setdefault(response_set_id, {"version": 0, "idempotency": {}, "company_id": company_id})

    def delete_answer(self, response_set_id: str, question_id: str) -> None:
        before = len(self.answers)
        self.answers = [a for a in self.answers if not (a.response_set_id == response_set_id and a.question_id == question_id)]
        # deletion increments version to reflect state change
        if before != len(self.answers) and response_set_id in self.response_sets:
            self.response_sets[response_set_id]["version"] += 1

    # -------------
    # GET handlers
    # -------------
    def get_screen(self, response_set_id: str, screen_id: str) -> Tuple[int, Dict[str, str], Dict[str, Any]]:
        screen = self.screens.get(screen_id)
        if not screen:
            problem = {"title": "Not Found", "status": 404}
            return 404, {"Content-Type": "application/problem+json"}, problem
        version = self.response_sets.get(response_set_id, {"version": 0}).get("version", 0)
        etag = f"v{version}"
        questions = [q for q in self.questions.values() if q.screen_id == screen_id]
        # Deterministic order by question_order asc, then question_id
        questions.sort(key=lambda x: (x.question_order, x.question_id))
        body = {
            "screen": {
                "screen_id": screen.screen_id,
                "screen_key": screen.screen_key,
                "title": screen.title,
                "order": screen.order,
            },
            "questions": [
                {
                    "question_id": q.question_id,
                    "external_qid": q.external_qid,
                    "question_text": q.question_text,
                    "answer_kind": q.answer_kind,
                    "mandatory": q.mandatory,
                    "question_order": q.question_order,
                }
                for q in questions
            ],
        }
        headers = {"ETag": etag, "Content-Type": "application/json"}
        return 200, headers, body

    def get_questionnaire(self, questionnaire_id: str) -> Tuple[int, Dict[str, str], Dict[str, Any]]:
        if questionnaire_id not in self.questionnaires:
            return 404, {"Content-Type": "application/problem+json"}, {"title": "Not Found", "status": 404}
        # Minimal positive path not used by scenarios; return basic structure
        q = self.questionnaires[questionnaire_id]
        return 200, {"Content-Type": "application/json"}, {"questionnaire_id": q.questionnaire_id, "key": q.key, "title": q.title}

    def export_questionnaire(self, questionnaire_id: str) -> Tuple[int, Dict[str, str], str]:
        if questionnaire_id not in self.questionnaires:
            return 404, {"Content-Type": "application/problem+json"}, json.dumps({"title": "Not Found", "status": 404})
        # Build rows from questions joined with screen key
        rows: List[Tuple[str, str, int, str, str, bool, str, str, str]] = []
        for q in self.questions.values():
            sc = self.screens[q.screen_id]
            options = "|".join(
                f"{opt.value}:{opt.label}" for opt in sorted(self.answer_options, key=lambda o: o.sort_index) if opt.question_id == q.question_id
            )
            rows.append(
                (
                    q.external_qid,
                    sc.screen_key,
                    q.question_order,
                    q.question_text,
                    q.answer_kind,
                    q.mandatory,
                    "",
                    options,
                    q.question_id,
                )
            )
        # Sort by screen_key asc, question_order asc, question_id asc
        rows.sort(key=lambda r: (r[1], r[2], r[8]))
        out = io.StringIO()
        writer = csv.writer(out)
        writer.writerow(
            [
                "external_qid",
                "screen_key",
                "question_order",
                "question_text",
                "answer_kind",
                "mandatory",
                "placeholder_code",
                "options",
            ]
        )
        for r in rows:
            writer.writerow([r[0], r[1], r[2], r[3], r[4], "true" if r[5] else "false", r[6], r[7]])
        csv_text = out.getvalue()
        headers = {"Content-Type": "text/csv; charset=utf-8", "ETag": f"W/\"{len(csv_text)}\""}
        return 200, headers, csv_text

    # --------------
    # POST handlers
    # --------------
    def post_regenerate_check(self, response_set_id: str) -> Tuple[int, Dict[str, str], Dict[str, Any]]:
        # Compute mandatory questions missing answers
        answered_qids = {a.question_id for a in self.answers if a.response_set_id == response_set_id}
        blocking: List[Dict[str, str]] = []
        for q in self.questions.values():
            if q.mandatory and q.question_id not in answered_qids:
                blocking.append({"question_id": q.question_id, "reason": "mandatory_missing"})
        ok = len(blocking) == 0
        headers = {"Content-Type": "application/json"}
        return 200, headers, {"ok": ok, "blocking_items": blocking}

    def post_import_csv(self, filename: str, content: str) -> Tuple[int, Dict[str, str], Dict[str, Any]]:
        # Parse CSV content and upsert questions; reject duplicates within the same file
        rows = list(csv.DictReader(io.StringIO(content.strip())))
        # Detect duplicates by external_qid within this file
        counts: Dict[str, int] = {}
        for r in rows:
            ext = (r.get("external_qid") or "").strip()
            if not ext:
                continue
            counts[ext] = counts.get(ext, 0) + 1
        dup_exts = [ext for ext, cnt in counts.items() if cnt > 1]
        errors: List[Dict[str, Any]] = []
        if dup_exts:
            # Emit one error per duplicate row occurrence beyond the first
            for idx, r in enumerate(rows, start=2):
                ext = (r.get("external_qid") or "").strip()
                if ext in dup_exts:
                    errors.append({"line": idx, "code": "duplicate_external_qid", "message": f"duplicate external_qid {ext}"})
            return 200, {"Content-Type": "application/json"}, {"created": 0, "updated": 0, "errors": errors}

        # Deletion semantics (CSV v1.0): remove any existing questions for the active
        # questionnaire that are not present in this file's external_qid set.
        incoming_exts = set(counts.keys())
        # Determine the active questionnaire used for screen bindings in this mock
        active_qid: Optional[str] = next(iter(self.questionnaires.keys()), None)
        if active_qid is not None:
            to_delete: List[Tuple[str, str]] = []  # (question_id, external_qid)
            for q in list(self.questions.values()):
                sc = self.screens.get(q.screen_id)
                if sc and sc.questionnaire_id == active_qid and q.external_qid not in incoming_exts:
                    to_delete.append((q.question_id, q.external_qid))
            if to_delete:
                # Remove questions, their options, and any answer rows
                del_ids = {qid for (qid, _ext) in to_delete}
                for qid, ext in to_delete:
                    # Drop from primary maps
                    self.questions.pop(qid, None)
                    # Drop external index only if pointing to this question id
                    if self.questions_by_external.get(ext) == qid:
                        self.questions_by_external.pop(ext, None)
                # Purge dependent rows
                self.answer_options = [o for o in self.answer_options if o.question_id not in del_ids]
                self.answers = [a for a in self.answers if a.question_id not in del_ids]

        updates = 0
        creates = 0
        for idx, row in enumerate(rows, start=2):  # header is line 1
            ext = (row.get("external_qid") or "").strip()
            if not ext:
                errors.append({"line": idx, "code": "missing_external_qid", "message": "external_qid is required"})
                continue
            screen_key = (row.get("screen_key") or "").strip()
            # map screen_key -> screen_id (create on first use)
            screen_id = None
            for sc in self.screens.values():
                if sc.screen_key == screen_key:
                    screen_id = sc.screen_id
                    break
            if screen_id is None:
                screen_id = _gen_uuid()
                # bind to first questionnaire (arbitrary within mock)
                first_qid = next(iter(self.questionnaires.keys())) if self.questionnaires else _gen_uuid()
                self.create_screen(screen_id, first_qid, screen_key, screen_key.title(), 999)

            try:
                question_order = int((row.get("question_order") or "0").strip() or "0")
            except Exception:
                question_order = 0
            question_text = row.get("question_text", "").strip()
            answer_kind = row.get("answer_kind", "").strip()
            mandatory = (row.get("mandatory", "false").strip().lower() in {"true", "1", "yes"})
            options_raw = row.get("options", "").strip()
            # Unescape escaped colons from feature input (e.g., "VALUE\:Label")
            options_raw = options_raw.replace('\\:', ':')

            if ext in self.questions_by_external:
                # update
                qid = self.questions_by_external[ext]
                q = self.questions[qid]
                q.question_order = question_order
                q.question_text = question_text
                q.answer_kind = answer_kind
                q.mandatory = mandatory
                updates += 1
                # reset options for the question
                self.answer_options = [o for o in self.answer_options if o.question_id != qid]
            else:
                # create
                qid = _gen_uuid()
                self.create_question(qid, screen_id, ext, question_text, answer_kind, mandatory, question_order)
                creates += 1

            if options_raw:
                parts = [p for p in options_raw.split("|") if p]
                for i, part in enumerate(parts, start=1):
                    if ":" in part:
                        val, label = part.split(":", 1)
                    else:
                        val, label = part, part
                    self.answer_options.append(AnswerOption(qid, val, label, i))

        # Final summary before return
        try:
            print(f"DEBUG csv_import_result: created={creates} updated={updates} errors={len(errors)}")
        except Exception:
            pass
        result = {"created": creates, "updated": updates, "errors": errors}
        return 200, {"Content-Type": "application/json"}, result

    # ---------------
    # PATCH handlers
    # ---------------
    def patch_answer(self, response_set_id: str, question_id: str, headers: Dict[str, str], body: Dict[str, Any]) -> Tuple[int, Dict[str, str], Dict[str, Any]]:
        # ETag precondition
        current_version = self.response_sets.get(response_set_id, {"version": 0}).get("version", 0)
        current_etag = f"v{current_version}"
        if_match = headers.get("If-Match")
        if if_match not in ("*", current_etag):
            problem = {"title": "Conflict", "status": 409, "detail": "stale etag"}
            return 409, {"Content-Type": "application/problem+json"}, problem

        # Basic request validation and type checking
        if body.get("question_id") != question_id:
            problem = {"title": "Unprocessable Entity", "status": 422, "errors": [{"path": "$.question_id", "message": "mismatch", "code": "invalid"}]}
            return 422, {"Content-Type": "application/problem+json"}, problem

        q = self.questions.get(question_id)
        if not q:
            problem = {"title": "Not Found", "status": 404}
            return 404, {"Content-Type": "application/problem+json"}, problem

        value = body.get("value")
        type_ok = self._validate_value(q.answer_kind, value)
        if not type_ok:
            problem = {
                "title": "Unprocessable Entity",
                "status": 422,
                "errors": [
                    {"path": "$.value", "message": "type mismatch", "code": "type_mismatch"},
                ],
            }
            return 422, {"Content-Type": "application/problem+json"}, problem

        # Idempotency key behavior (do not mutate state if same key/value repeats)
        rs_state = self.response_sets.setdefault(response_set_id, {"version": 0, "idempotency": {}})
        idem_key = headers.get("Idempotency-Key")
        if idem_key:
            idem_map = rs_state["idempotency"]
            key = (question_id, idem_key)
            if key in idem_map and idem_map[key] == value:
                # return identical etag (no version bump)
                headers_out = {"ETag": current_etag, "Content-Type": "application/json"}
                return 200, headers_out, {"saved": True, "etag": current_etag}

        # Upsert answer (single row per response_set_id+question_id)
        updated = False
        for row in self.answers:
            if row.response_set_id == response_set_id and row.question_id == question_id:
                row.value = value
                updated = True
                break
        if not updated:
            self.answers.append(AnswerRow(response_set_id, question_id, value))

        # Mutating state bumps etag
        rs_state["version"] = rs_state.get("version", 0) + 1
        new_etag = f"v{rs_state['version']}"
        if idem_key:
            rs_state["idempotency"][(question_id, idem_key)] = value
        headers_out = {"ETag": new_etag, "Content-Type": "application/json"}
        return 200, headers_out, {"saved": True, "etag": new_etag}

    @staticmethod
    def _validate_value(answer_kind: str, value: Any) -> bool:
        if answer_kind == "short_string":
            return isinstance(value, str)
        if answer_kind == "number":
            return isinstance(value, int)
        if answer_kind == "boolean":
            return isinstance(value, bool)
        if answer_kind.startswith("enum_"):
            return isinstance(value, str)
        return True


# ------------------
# Behave step helpers
# ------------------


def _load_schema(name: str) -> Dict[str, Any]:
    path = f"schemas/{name}"
    with open(path, "r", encoding="utf-8") as fh:
        return json.load(fh)
from functools import lru_cache


@lru_cache(maxsize=1)
def _schemas() -> Dict[str, Any]:
    """Lazy-load and cache all schemas on first use to avoid import-time IO."""
    return {
        "AutosaveResult": _load_schema("AutosaveResult.schema.json"),
        "RegenerateCheckResult": _load_schema("RegenerateCheckResult.schema.json"),
        "ImportResult": _load_schema("ImportResult.schema.json"),
        "Problem": _load_schema("Problem.schema.json"),
        "ValidationProblem": _load_schema("ValidationProblem.schema.json"),
        "CSVExportSnapshot": _load_schema("CSVExportSnapshot.schema.json"),
        "ResponseSetId": _load_schema("ResponseSetId.schema.json"),
        "ScreenId": _load_schema("ScreenId.schema.json"),
        "QuestionId": _load_schema("QuestionId.schema.json"),
        "QuestionnaireId": _load_schema("QuestionnaireId.schema.json"),
        "AnswerUpsert": _load_schema("AnswerUpsert.schema.json"),
        "CSVImportFile": _load_schema("CSVImportFile.schema.json"),
    }


def _schema(name: str) -> Dict[str, Any]:
    return _schemas()[name]


@lru_cache(maxsize=1)
def _schema_store() -> Dict[str, Dict[str, Any]]:
    store: Dict[str, Dict[str, Any]] = {}
    for sch in _schemas().values():
        _sid = sch.get("$id")
        if isinstance(_sid, str) and _sid:
            store[_sid] = sch
    # Optionally include ValidationItem if present
    try:
        _validation_item = _load_schema("ValidationItem.schema.json")
        _sid_vi = _validation_item.get("$id")
        if isinstance(_sid_vi, str) and _sid_vi:
            store[_sid_vi] = _validation_item
    except Exception:
        pass
    return store


def _validate(instance: Any, schema: Dict[str, Any]) -> None:
    """Validate an instance against a JSON Schema using a local $ref resolver.

    Uses Draft 2020-12 with FormatChecker and a RefResolver backed by the
    in-memory store built from local schema files.
    """
    if Draft202012Validator is None or FormatChecker is None or RefResolver is None:
        raise AssertionError(
            f"jsonschema is required for integration validation but is unavailable: {_JSONSCHEMA_IMPORT_ERROR}"
        )
    validator = Draft202012Validator(
        schema,
        format_checker=FormatChecker(),
        resolver=RefResolver.from_schema(schema, store=_schema_store()),
    )
    validator.validate(instance)


def _is_uuid_str(value: Any) -> bool:
    return isinstance(value, str) and _try_parse_uuid(value)


def _try_parse_uuid(value: str) -> bool:
    try:
        uuid.UUID(value)
        return True
    except Exception:
        return False


def _fallback_validate(instance: Any, schema_name: str) -> None:
    # Lightweight checks by schema name when jsonschema is unavailable.
    if schema_name in {"QuestionnaireId", "ResponseSetId", "ScreenId", "QuestionId"}:
        assert isinstance(instance, str) and _is_uuid_str(instance), (
            f"{schema_name} must be a UUID string"
        )
        return
    if schema_name == "Problem":
        assert isinstance(instance, dict), "Problem must be an object"
        assert isinstance(instance.get("title"), str), "Problem.title must be a string"
        assert isinstance(instance.get("status"), int), "Problem.status must be an integer"
        return
    if schema_name == "ValidationProblem":
        _fallback_validate(instance, "Problem")
        assert isinstance(instance.get("errors"), list), "ValidationProblem.errors must be a list"
        return
    if schema_name == "AutosaveResult":
        assert isinstance(instance, dict), "AutosaveResult must be an object"
        assert isinstance(instance.get("saved"), bool), "AutosaveResult.saved must be boolean"
        et = instance.get("etag")
        assert isinstance(et, str) and et.strip(), "AutosaveResult.etag must be a non-empty string"
        return
    if schema_name == "RegenerateCheckResult":
        assert isinstance(instance, dict), "RegenerateCheckResult must be an object"
        assert isinstance(instance.get("ok"), bool), "RegenerateCheckResult.ok must be boolean"
        items = instance.get("blocking_items")
        assert isinstance(items, list), "RegenerateCheckResult.blocking_items must be a list"
        for it in items:
            assert isinstance(it, dict), "blocking_items[] must be objects"
            assert _is_uuid_str(it.get("question_id")), "blocking_items[].question_id must be a UUID string"
            assert isinstance(it.get("reason"), str), "blocking_items[].reason must be a string"
        return
    if schema_name in {"CSVImportFile", "CSVExportSnapshot"}:
        assert isinstance(instance, str), f"{schema_name} must be a string"
        return
    # Unknown schema: best-effort pass
    return


def _validate_with_name(instance: Any, schema_name: str) -> None:
    try:
        _validate(instance, _schema(schema_name))
    except Exception:
        # Fallback minimal validation if jsonschema missing
        _fallback_validate(instance, schema_name)


def _jsonpath(obj: Dict[str, Any], path: str) -> Any:
    # Very small subset: $.a.b and $.a[0] and $.a.length()
    if not path.startswith("$"):
        raise AssertionError("JSONPath must start with $")
    cur: Any = obj
    tokens = path[1:].strip().lstrip(".").split(".") if path != "$" else []
    for tok in tokens:
        if tok.endswith("()") and tok[:-2] == "length":
            # Special-case length() for arrays
            return len(cur)
        if "[" in tok and tok.endswith("]"):
            name, idx_str = tok.split("[", 1)
            idx = int(idx_str[:-1])
            cur = cur[name][idx]
        elif tok.startswith("[") and tok.endswith("]") and "?(@." in tok:
            # Very small subset for filter: $..[?(@.field=='value')].field2
            # Example: $.questions[?(@.question_id=='...')].answer_kind
            # We support extracting a list of matched rows and then tailing attribute name in next token.
            cond = tok[len("[") : -1]
            assert cond.startswith("?(@.") and "==" in cond, "Unsupported filter expression"
            left, right = cond[3:].split("==", 1)
            left = left.strip().strip(".")
            right = right.strip().strip("'").strip('"')
            cur = [item for item in cur if str(item.get(left)) == right]
        else:
            cur = cur[tok]
    return cur


def _jsonpath(data: Any, path: str) -> Any:  # override with robust evaluator
    # Minimal JSONPath evaluator for patterns used in feature file.
    # Unescape feature-escaped characters before processing.
    # Replacements: "\\$"->"$", "\\."->".", "\\["->"[", "\\]"->"]", "\\_"->"_".
    def _compact_repr(obj: Any, max_len: int = 240) -> str:
        try:
            s = json.dumps(obj, ensure_ascii=False, separators=(",", ":"))
        except Exception:
            s = repr(obj)
        if len(s) > max_len:
            return s[: max_len - 3] + "..."
        return s

    original_path = path
    path = (
        path.replace("\\$", "$")
        .replace("\\.", ".")
        .replace("\\[", "[")
        .replace("\\]", "]")
        .replace("\\_", "_")
    )
    unescaped_path = path
    assert path.startswith("$"), (
        "Unsupported path: {p}\nUnescaped: {u}\nSource: {s}".format(
            p=original_path, u=unescaped_path, s=_compact_repr(data)
        )
    )
    # Handle length() suffix
    if path.endswith(".length()"):
        base = path[:-10]
        try:
            arr = _jsonpath(data, base)
        except AssertionError as exc:
            raise AssertionError(
                f"length() base failed for path={original_path} (unescaped={unescaped_path}): {exc}"
            )
        try:
            return len(arr)
        except Exception as exc:
            raise AssertionError(
                "length() target not sized. path={p} unescaped={u} segment={s} error={e}".format(
                    p=original_path, u=unescaped_path, s=_compact_repr(arr), e=exc
                )
            )
    # Handle array index, e.g. $.errors[0].path
    # and filter: $.questions[?(@.question_id=='...')].answer_kind
    if "[?(@." in path:
        try:
            prefix, rest = path.split("[?(@.", 1)
            field, rest2 = rest.split("=='", 1)
            value, tail = rest2.split("')]")
        except Exception as exc:
            raise AssertionError(
                f"Malformed filter in path={original_path} (unescaped={unescaped_path}): {exc}"
            )
        arr = _jsonpath(data, prefix)
        assert isinstance(arr, list), (
            "Filter applies to a list. path={p} unescaped={u} segment={s}".format(
                p=original_path, u=unescaped_path, s=_compact_repr(arr)
            )
        )
        matched = None
        for item in arr:
            if isinstance(item, dict) and str(item.get(field)) == value:
                matched = item
                break
        assert matched is not None, (
            "No item matched {f}=='{v}'. path={p} unescaped={u} segment={s}".format(
                f=field, v=value, p=original_path, u=unescaped_path, s=_compact_repr(arr)
            )
        )
        if tail:
            if tail.startswith("."):
                return _jsonpath(matched, "$" + tail)
        return matched
    # Simple dot navigation with optional array index like [0]
    cur: Any = data
    tokens = path[2:].split(".") if path.startswith("$.") else []
    for tok in tokens:
        try:
            if tok.endswith("]") and "[" in tok:
                name, idx_str = tok[:-1].split("[")
                if name:
                    try:
                        cur = cur[name]
                    except Exception as exc:
                        raise AssertionError(
                            "Key '{k}' not found. path={p} unescaped={u} segment={s} error={e}".format(
                                k=name, p=original_path, u=unescaped_path, s=_compact_repr(cur), e=exc
                            )
                        )
                try:
                    idx = int(idx_str)
                except Exception as exc:
                    raise AssertionError(
                        f"Invalid index '{idx_str}'. path={original_path} unescaped={unescaped_path}: {exc}"
                    )
                try:
                    cur = cur[idx]
                except Exception as exc:
                    raise AssertionError(
                        "Index {i} out of range. path={p} unescaped={u} segment={s} error={e}".format(
                            i=idx, p=original_path, u=unescaped_path, s=_compact_repr(cur), e=exc
                        )
                    )
            else:
                try:
                    cur = cur[tok]
                except Exception as exc:
                    raise AssertionError(
                        "Key '{k}' not found. path={p} unescaped={u} segment={s} error={e}".format(
                            k=tok, p=original_path, u=unescaped_path, s=_compact_repr(cur), e=exc
                        )
                    )
        except AssertionError:
            raise
        except Exception as exc:
            raise AssertionError(
                "Traversal error at token '{t}'. path={p} unescaped={u} segment={s} error={e}".format(
                    t=tok, p=original_path, u=unescaped_path, s=_compact_repr(cur), e=exc
                )
            )
    return cur


def _substitute_vars(context: Any, s: str) -> str:
    out = s
    for k, v in getattr(context, "vars", {}).items():
        out = out.replace("{" + k + "}", str(v))
    return out


def _append_failure_jsonl(context: Any, record: Dict[str, Any]) -> None:
    base = {
        "feature": getattr(getattr(context, "feature", None), "name", None),
        "scenario": getattr(getattr(context, "scenario", None), "name", None),
        "method": (getattr(context, "last_response", {}) or {}).get("method"),
        "path": (getattr(context, "last_response", {}) or {}).get("path"),
        "status": (getattr(context, "last_response", {}) or {}).get("status"),
    }
    # Enrich with context about the last operation for easier diagnosis
    try:
        method = base.get("method")
        path = base.get("path") or ""
        body = (getattr(context, "last_response", {}) or {}).get("json")
        text_body = (getattr(context, "last_response", {}) or {}).get("text")
        # Include a generic body preview for any failure
        try:
            if body is not None:
                preview = json.dumps(body, ensure_ascii=False, separators=(",", ":"))
                base["body_preview"] = preview[:500]
            elif isinstance(text_body, str):
                base["body_preview"] = text_body[:200]
        except Exception:
            pass
        if method == "POST" and path.endswith("/regenerate-check") and isinstance(body, dict):
            # compact body excerpt for gating context
            excerpt = json.dumps(body, separators=(",", ":"))
            base["body_excerpt"] = excerpt[:500]
            try:
                phase = getattr(context, "_gating_phase_label", None)
                if phase:
                    base["phase"] = phase
            except Exception:
                pass
            try:
                base["blocking_count"] = len(body.get("blocking_items", []))
                base["ok"] = body.get("ok")
            except Exception:
                pass
        if method == "POST" and path == "/questionnaires/import" and isinstance(body, dict):
            base["created"] = body.get("created")
            base["updated"] = body.get("updated")
            errors_list = body.get("errors") or []
            base["errors_len"] = len(errors_list) if isinstance(errors_list, list) else None
            try:
                base["questions_by_external_keys"] = sorted(list(getattr(context.sut, "questions_by_external", {}).keys()))
                base["has_q_dup"] = ("Q_DUP" in getattr(context.sut, "questions_by_external", {}))
            except Exception:
                pass
        if method == "PATCH" and "/answers/" in path:
            # 422 details and DB preservation snapshot
            if base.get("status") == 422 and isinstance(body, dict):
                try:
                    err0 = (body.get("errors") or [None])[0] or {}
                    base["error0_path"] = err0.get("path")
                    base["error0_code"] = err0.get("code")
                    base["error0_message"] = err0.get("message")
                    base["envelope_schema"] = "ValidationProblem"
                except Exception:
                    pass
            # Include body for conflict path diagnostics
            if isinstance(body, dict):
                try:
                    base["body"] = body
                except Exception:
                    pass
            # DB row value snapshot
            try:
                parts = path.strip("/").split("/")
                rs_id = parts[1]
                q_id = parts[-1]
                rows = [a for a in getattr(context.sut, "answers", []) if a.response_set_id == rs_id and a.question_id == q_id]
                base["db_answer_value"] = rows[0].value if rows else None
            except Exception:
                pass
        if method == "GET" and isinstance(body, dict):
            # For 404 problem json checks
            base["problem_status"] = body.get("status")
    except Exception:
        pass
    out = {**base, **record}
    try:
        os.makedirs("logs", exist_ok=True)
        with open(os.path.join("logs", "behave_failures.jsonl"), "a", encoding="utf-8") as fh:
            fh.write(json.dumps(out, ensure_ascii=False) + "\n")
    except Exception:
        # Best-effort; do not mask step failures
        pass


# ----------------
# Given steps
# ----------------


@given("a clean database")
def step_clean_db(context):
    context.sut = MockQuestionnaireService()
    context.vars = {}
    context.last_response = {"status": None, "headers": {}, "json": None, "text": None, "path": None, "method": None}


@given("the following questionnaire exists in the database:")
def step_setup_questionnaire(context):
    for row in context.table:
        context.sut.create_questionnaire(row[0], row[1], row[2])


@given('the following screens exist for questionnaire "{questionnaire_id}"')
def step_setup_screens(context, questionnaire_id: str):
    for row in context.table:
        screen_id, screen_key, title, order_str = row[0], row[1], row[2], row[3]
        context.sut.create_screen(screen_id, questionnaire_id, screen_key, title, int(order_str))


@given('the following questions exist and are bound to screen "{screen_id}"')
def step_setup_questions(context, screen_id: str):
    for row in context.table:
        question_id, external_qid, question_text, answer_kind, mandatory_str, question_order_str = (
            row[0], row[1], row[2], row[3], row[4], row[5]
        )
        context.sut.create_question(
            question_id,
            screen_id,
            external_qid,
            question_text,
            answer_kind,
            mandatory_str.strip().lower() in {"true", "1", "yes"},
            int(question_order_str),
        )


@given("an empty response set exists:")
def step_setup_response_set(context):
    for row in context.table:
        rs_id, company_id = row[0], row[1]
        context.sut.ensure_response_set(rs_id, company_id)


@given('no answers exist yet for response set "{response_set_id}"')
def step_no_answers_for_rs(context, response_set_id: str):
    assert sum(1 for a in context.sut.answers if a.response_set_id == response_set_id) == 0


@given('I GET "{path}" and capture header "{header_name}" as "{var_name}"')
@when('I GET "{path}" and capture header "{header_name}" as "{var_name}"')
def step_get_and_capture(context, path: str, header_name: str, var_name: str):
    step_when_get(context, path)
    val = context.last_response["headers"].get(header_name)
    assert val and isinstance(val, str) and val.strip(), f"Missing/empty header {header_name}"
    context.vars[var_name] = val
    # ETag capture diagnostics
    try:
        method = context.last_response.get("method")
        req_path = context.last_response.get("path")
        status = context.last_response.get("status")
    except Exception:
        method = req_path = status = None
    print(
        f"DEBUG etag_capture: method={method} path={req_path} status={status} header={header_name} var={var_name} value={val}"
    )


@given('I DELETE any answer in table "answer" for (response_set_id="{rs_id}", question_id="{q_id}")')
@given('I DELETE any answer in table "answer" for (response\\_set\\_id="{rs_id}", question\\_id="{q_id}")')
def step_delete_answer(context, rs_id: str, q_id: str):
    context.sut.delete_answer(rs_id, q_id)


# ----------------
# When steps
# ----------------


@when('I GET "{path}"')
def step_when_get(context, path: str):
    path = _substitute_vars(context, path)
    status: int
    headers: Dict[str, str]
    body_json: Optional[Dict[str, Any]] = None
    body_text: Optional[str] = None
    if path.startswith("/response-sets/") and "/screens/" in path:
        parts = path.strip("/").split("/")
        rs_id = parts[1]
        screen_id = parts[-1]
        # Validate identifiers against schemas before invoking SUT
        try:
            _validate_with_name(rs_id, "ResponseSetId")  # may raise
            _validate_with_name(screen_id, "ScreenId")  # may raise
        except Exception as exc:
            raise AssertionError(f"Schema validation failed for path IDs: {exc}")
        status, headers, body_json = context.sut.get_screen(rs_id, screen_id)
    elif path.startswith("/questionnaires/") and path.endswith("/export"):
        qid = path.strip("/").split("/")[1]
        # Validate identifier prior to export
        try:
            _validate_with_name(qid, "QuestionnaireId")  # may raise
        except Exception as exc:
            raise AssertionError(f"Schema validation failed for questionnaire_id: {exc}")
        status, headers, body_text = context.sut.export_questionnaire(qid)
        # If export returns an error with problem+json, surface JSON for assertions and schema validation
        if status >= 400 and headers.get("Content-Type", "").startswith("application/problem+json") and body_text:
            try:
                body_json = json.loads(body_text)
            except Exception:
                body_json = None
            # Validate problem+json envelope for 4xx export errors
            if body_json is not None:
                try:
                    _validate_with_name(body_json, "Problem")
                except Exception as exc:
                    raise AssertionError(f"Schema validation failed for Problem error envelope (export): {exc}")
    elif path.startswith("/questionnaires/"):
        qid = path.strip("/").split("/")[1]
        # Validate identifier prior to fetch
        try:
            _validate_with_name(qid, "QuestionnaireId")  # may raise
        except Exception as exc:
            raise AssertionError(f"Schema validation failed for questionnaire_id: {exc}")
        status, headers, body_json = context.sut.get_questionnaire(qid)
        # Validate 4xx responses against Problem schema
        if status >= 400 and body_json is not None:
            try:
                _validate_with_name(body_json, "Problem")
            except Exception as exc:
                raise AssertionError(f"Schema validation failed for Problem error envelope (get): {exc}")
    else:
        status, headers, body_json = 404, {"Content-Type": "application/problem+json"}, {"title": "Not Found", "status": 404}

    context.last_response = {
        "status": status,
        "headers": headers,
        "json": body_json,
        "text": body_text,
        "path": path,
        "method": "GET",
    }
    # Single-line snapshot: method, path, status, headers keys, has_json, has_text
    try:
        hdr_keys = sorted(list((headers or {}).keys())) if isinstance(headers, dict) else []
        has_json = body_json is not None
        has_text = body_text is not None
        print(
            f"DEBUG get_snapshot: method=GET path={path} status={status} headers_keys={hdr_keys} has_json={has_json} has_text={has_text}"
        )
    except Exception:
        pass
    # CSV export success-path schema validation (text/csv)
    if path.endswith("/export") and context.last_response["status"] == 200:
        ctype = context.last_response["headers"].get("Content-Type", "")
        if ctype.startswith("text/csv"):
            try:
                _validate_with_name(context.last_response["text"], "CSVExportSnapshot")  # may raise
            except Exception as exc:
                raise AssertionError(f"Schema validation failed for CSV export: {exc}")
        # After export, print length of CSV and ETag value
        try:
            et = context.last_response.get("headers", {}).get("ETag")
            txt = context.last_response.get("text") or ""
            print(f"DEBUG csv_export_snapshot: etag={et} length={len(txt)}")
        except Exception:
            pass


@when('I PATCH "{path}" with headers:')
@given('I PATCH "{path}" with headers:')
def step_when_patch_headers(context, path: str):
    headers_table = context.table
    headers: Dict[str, str] = {}
    for row in headers_table:
        key = row[0]
        val = _substitute_vars(context, row[1])
        # Normalize If-Match header: strip surrounding single/double quotes
        # Accept both '*' and '"*"' as equivalent for wildcard precondition
        if isinstance(val, str) and key.lower() == "if-match":
            v = val.strip()
            if len(v) >= 2 and (v[0] == v[-1]) and v[0] in ('"', "'"):
                v = v[1:-1]
            val = v
        headers[key] = val
    # Body must follow in feature; capture in context until body step runs
    context._pending_patch = {"path": path, "headers": headers}


@when("And body:")
def step_when_and_body(context):
    # Delegate to the JSON body handler so PATCH executes as intended
    return step_when_body(context)


@when("body:")
@given("body:")
def step_when_body(context):
    assert hasattr(context, "_pending_patch"), "PATCH headers must be provided before body"
    path = _substitute_vars(context, context._pending_patch["path"])  # type: ignore[index]
    headers = context._pending_patch["headers"]  # type: ignore[index]
    # Parse JSON body
    try:
        payload = json.loads(context.text)
    except Exception as exc:
        raise AssertionError(f"Invalid JSON body: {exc}")
    # Minimal request validation per spec: require question_id (UUID) and presence of value
    try:
        assert isinstance(payload, dict), "PATCH payload must be an object"
        assert "question_id" in payload, "PATCH payload must include question_id"
        _validate_with_name(payload["question_id"], "QuestionId")
        assert "value" in payload, "PATCH payload must include value"
    except Exception as exc:
        raise AssertionError(f"Invalid PATCH payload: {exc}")
    # Enrich payload with answer_kind from SUT question definition if missing (Clarke requirement)
    try:
        # Derive question_id from the PATCH path
        assert path.startswith("/response-sets/") and "/answers/" in path, "Unsupported PATCH path"
        _parts = path.strip("/").split("/")
        _q_id = _parts[-1]
        # Look up the question and its answer_kind
        _q = getattr(context, "sut").questions.get(_q_id)  # type: ignore[attr-defined]
        if isinstance(_q, dict):
            _kind = _q.get("answer_kind")
        else:
            _kind = getattr(_q, "answer_kind", None)
        if _kind and "answer_kind" not in payload:
            payload["answer_kind"] = _kind
    except Exception:
        # Do not fail enrichment; schema validation below will surface issues
        pass

    # Validate full payload against AnswerUpsert schema after enrichment
    try:
        _validate_with_name(payload, "AnswerUpsert")
    except Exception as exc:
        raise AssertionError(f"Schema validation failed for AnswerUpsert: {exc}")

    # Determine route
    assert path.startswith("/response-sets/") and "/answers/" in path, "Unsupported PATCH path"
    parts = path.strip("/").split("/")
    rs_id = parts[1]
    q_id = parts[-1]
    try:
        _validate_with_name(rs_id, "ResponseSetId")
        _validate_with_name(q_id, "QuestionId")
    except Exception as exc:
        raise AssertionError(f"Schema validation failed for path IDs: {exc}")

    status, resp_headers, body = context.sut.patch_answer(rs_id, q_id, headers, payload)  # type: ignore[arg-type]
    context.last_response = {
        "status": status,
        "headers": resp_headers,
        "json": body,
        "text": None,
        "path": path,
        "method": "PATCH",
    }
    # Response schema (success or problem)
    try:
        if status == 200:
            _validate_with_name(body, "AutosaveResult")
        elif status in {409, 404}:
            _validate_with_name(body, "Problem")
        elif status == 422:
            _validate_with_name(body, "ValidationProblem")
    except Exception as exc:
        raise AssertionError(f"Response schema invalid for PATCH {path}: {exc}")
    # Emit concise snapshot for CI logs
    try:
        hdr_keys = sorted(list((resp_headers or {}).keys())) if isinstance(resp_headers, dict) else []
        print(
            f"DEBUG patch_snapshot: method=PATCH path={path} status={status} headers_keys={hdr_keys} body_keys={(sorted(list(body.keys())) if isinstance(body, dict) else None)}"
        )
    except Exception:
        pass


@when('I POST "{path}"')
def step_when_post(context, path: str):
    path = _substitute_vars(context, path)
    status: int
    headers: Dict[str, str]
    body: Dict[str, Any]
    if path.endswith("/regenerate-check"):
        # For diagnostics labeling
        try:
            setattr(context, "_gating_phase_label", getattr(context, "_gating_phase_label", None) or "pre")
        except Exception:
            pass
        rs_id = path.strip("/").split("/")[1]
        try:
            _validate_with_name(rs_id, "ResponseSetId")
        except Exception as exc:
            raise AssertionError(f"Schema validation failed for response_set_id: {exc}")
        status, headers, body = context.sut.post_regenerate_check(rs_id)
        # Label phase to distinguish pre/post completion in logs
        try:
            setattr(context, "_gating_phase_label", "post")
        except Exception:
            pass
        # Validate response envelope
        try:
            _validate_with_name(body, "RegenerateCheckResult")
        except Exception as exc:
            raise AssertionError(f"Schema validation failed for RegenerateCheckResult: {exc}")
    else:
        status, headers, body = 404, {"Content-Type": "application/problem+json"}, {"title": "Not Found", "status": 404}
    context.last_response = {
        "status": status,
        "headers": headers,
        "json": body,
        "text": None,
        "path": path,
        "method": "POST",
    }
    try:
        hdr_keys = sorted(list((headers or {}).keys())) if isinstance(headers, dict) else []
        print(
            f"DEBUG post_snapshot: method=POST path={path} status={status} headers_keys={hdr_keys} body_keys={(sorted(list(body.keys())) if isinstance(body, dict) else None)}"
        )
    except Exception:
        pass


@when('I POST "{path}" with multipart file "{filename}" containing:')
def step_when_post_multipart(context, path: str, filename: str):
    path = _substitute_vars(context, path)
    if path != "/questionnaires/import":
        raise AssertionError("Only /questionnaires/import is supported for multipart in these steps")
    content = context.text or ""
    # Validate import CSV payload against schema (string type)
    try:
        _validate_with_name(content, "CSVImportFile")
    except Exception as exc:
        raise AssertionError(f"Schema validation failed for CSV import file: {exc}")
    status, headers, body = context.sut.post_import_csv(filename, content)
    # Validate import result envelope
    try:
        _validate_with_name(body, "ImportResult")
    except Exception as exc:
        raise AssertionError(f"Schema validation failed for ImportResult: {exc}")
    context.last_response = {
        "status": status,
        "headers": headers,
        "json": body,
        "text": None,
        "path": path,
        "method": "POST",
    }
    try:
        hdr_keys = sorted(list((headers or {}).keys())) if isinstance(headers, dict) else []
        print(
            f"DEBUG post_import_snapshot: method=POST path={path} status={status} headers_keys={hdr_keys} body_keys={(sorted(list(body.keys())) if isinstance(body, dict) else None)}"
        )
    except Exception:
        pass


# ----------------
# Then steps
# ----------------


@then("the response code should be {code:d}")
def step_then_status(context, code: int):
    actual = context.last_response["status"]
    try:
        assert actual == code, f"Expected {code}, got {actual}"
    except AssertionError:
        _append_failure_jsonl(context, {"expected_status": code, "actual_status": actual})
        raise


@then('the response header "{header_name}" should be a non-empty string')
def step_then_header_nonempty(context, header_name: str):
    headers = context.last_response["headers"]
    val = headers.get(header_name)
    assert isinstance(val, str) and val.strip(), f"Expected non-empty header {header_name}"


@then('the response header "{header_name}" equals "{expected}"')
def step_then_header_equals(context, header_name: str, expected: str):
    headers = context.last_response["headers"]
    val = headers.get(header_name)
    # Unescape feature-escaped underscores
    expected = expected.replace('\\_', '_')
    try:
        assert val == expected, f"Expected header {header_name}={expected}, got {val}"
    except AssertionError:
        _append_failure_jsonl(context, {"header": header_name, "expected": expected, "actual": val})
        raise


@then('the response header "{header_name}" should be a non-empty string and capture as "{var_name}"')
def step_then_header_capture(context, header_name: str, var_name: str):
    headers = context.last_response["headers"]
    val = headers.get(header_name)
    assert isinstance(val, str) and val.strip(), f"Expected non-empty header {header_name}"
    context.vars[var_name] = val


@then('the response JSON at "{json_path}" equals {expected:d}')
def step_then_json_equals_int(context, json_path: str, expected: int):
    body = context.last_response["json"]
    assert isinstance(body, dict), "No JSON body in response"
    actual = _jsonpath(body, json_path)
    try:
        assert actual == expected, f"Expected {expected} at {json_path}, got {actual}"
    except AssertionError as e:
        try:
            method = context.last_response.get("method")
            path = context.last_response.get("path")
            status = context.last_response.get("status")
        except Exception:
            method = path = status = None
        print(f"[behave] ASSERT FAIL: method={method} path={path} status={status} json_path={json_path} expected={expected!r} actual={actual!r}")
        _append_failure_jsonl(
            context,
            {
                "step": "assertion",
                "json_path": json_path,
                "expected": expected,
                "actual": actual,
            },
        )
        raise


@then('the response JSON at "{json_path}" equals "{expected}"')
def step_then_json_equals_string(context, json_path: str, expected: str):
    body = context.last_response["json"]
    assert isinstance(body, dict), "No JSON body in response"
    actual = _jsonpath(body, json_path)
    # Unescape feature-escaped underscores in the expected string
    expected = expected.replace('\\_', '_')
    # Diagnostics: surface assertion context in CI logs
    try:
        method = context.last_response.get("method")
        path = context.last_response.get("path")
        status = context.last_response.get("status")
    except Exception:
        method = path = status = None
    print(
        f"DEBUG json_equals_string: method={method} path={path} status={status} json_path={json_path} actual={actual!r} expected={expected!r}"
    )
    # Log full payload preview (JSON/text) truncated to 500 chars
    try:
        lr = context.last_response or {}
        if lr.get("json") is not None:
            payload = json.dumps(lr.get("json"), ensure_ascii=False, separators=(",", ":"))
            if len(payload) > 500:
                payload = payload[:497] + "..."
            print(f"DEBUG payload_json_preview: {payload}")
        elif lr.get("text") is not None:
            txt = lr.get("text") or ""
            print(f"DEBUG payload_text_preview: {txt[:500]}")
    except Exception:
        pass
    try:
        assert actual == expected, f"Expected '{expected}' at {json_path}, got {actual}"
    except AssertionError as e:
        try:
            method = context.last_response.get("method")
            path = context.last_response.get("path")
            status = context.last_response.get("status")
        except Exception:
            method = path = status = None
        print(f"[behave] ASSERT FAIL: method={method} path={path} status={status} json_path={json_path} expected={expected!r} actual={actual!r}")
        try:
            body = context.last_response.get("json")
            if isinstance(body, dict):
                snap = json.dumps(body, ensure_ascii=False, separators=(",", ":"))
                print(f"[behave] JSON SNAPSHOT: {snap[:500]}")
        except Exception:
            pass
        _append_failure_jsonl(
            context,
            {
                "step": "assertion",
                "json_path": json_path,
                "expected": expected,
                "actual": actual,
            },
        )
        raise


@then('the response JSON at "{json_path}" equals {expected}')
def step_then_json_equals_literal(context, json_path: str, expected: str):
    body = context.last_response["json"]
    assert isinstance(body, dict), "No JSON body in response"
    actual = _jsonpath(body, json_path)
    # Interpret some literals: [] and numbers and booleans and quoted strings
    exp: Any
    if expected == "[]":
        exp = []
    elif expected in ("true", "false"):
        exp = True if expected == "true" else False
    elif expected.isdigit():
        exp = int(expected)
    elif expected.startswith('"') and expected.endswith('"'):
        exp = expected[1:-1]
        # Unescape feature-escaped underscores in quoted strings
        exp = exp.replace('\\_', '_')
    else:
        # Fallback raw comparison
        exp = expected
    try:
        method = context.last_response.get("method")
        path = context.last_response.get("path")
        status = context.last_response.get("status")
    except Exception:
        method = path = status = None
    print(
        f"DEBUG json_equals_literal: method={method} path={path} status={status} json_path={json_path} actual={actual!r} expected={exp!r}"
    )
    # Log full payload preview (JSON/text) truncated to 500 chars
    try:
        lr = context.last_response or {}
        if lr.get("json") is not None:
            payload = json.dumps(lr.get("json"), ensure_ascii=False, separators=(",", ":"))
            if len(payload) > 500:
                payload = payload[:497] + "..."
            print(f"DEBUG payload_json_preview: {payload}")
        elif lr.get("text") is not None:
            txt = lr.get("text") or ""
            print(f"DEBUG payload_text_preview: {txt[:500]}")
    except Exception:
        pass
    try:
        assert actual == exp, f"Expected {exp} at {json_path}, got {actual}"
    except AssertionError as e:
        try:
            method = context.last_response.get("method")
            path = context.last_response.get("path")
            status = context.last_response.get("status")
        except Exception:
            method = path = status = None
        print(f"[behave] ASSERT FAIL: method={method} path={path} status={status} json_path={json_path} expected={exp!r} actual={actual!r}")
        try:
            body = context.last_response.get("json")
            if isinstance(body, dict):
                snap = json.dumps(body, ensure_ascii=False, separators=(",", ":"))
                print(f"[behave] JSON SNAPSHOT: {snap[:500]}")
        except Exception:
            pass
        _append_failure_jsonl(
            context,
            {
                "step": "assertion",
                "json_path": json_path,
                "expected": exp,
                "actual": actual,
            },
        )
        raise


@then('the response JSON at "{json_path}" is greater than {n:d}')
def step_then_json_greater_than(context, json_path: str, n: int):
    body = context.last_response["json"]
    actual = _jsonpath(body, json_path)
    try:
        assert isinstance(actual, int) and actual > n, f"Expected value > {n} at {json_path}, got {actual}"
    except AssertionError as e:
        try:
            method = context.last_response.get("method")
            path = context.last_response.get("path")
            status = context.last_response.get("status")
        except Exception:
            method = path = status = None
        expected = f"> {n}"
        print(f"[behave] ASSERT FAIL: method={method} path={path} status={status} json_path={json_path} expected={expected!r} actual={actual!r}")
        _append_failure_jsonl(
            context,
            {
                "step": "assertion",
                "json_path": json_path,
                "expected": expected,
                "actual": actual,
            },
        )
        raise


@then('the database table "answer" should have {n:d} rows for response\\_set\\_id "{rs_id}"')
def step_then_answer_rows_for_rs(context, n: int, rs_id: str):
    count = sum(1 for a in context.sut.answers if a.response_set_id == rs_id)
    assert count == n, f"Expected {n} rows, got {count}"


@then('the database should contain exactly {n:d} row in "answer" for (response\\_set\\_id="{rs_id}", question\\_id="{q_id}") with value "{val}"')
def step_then_exact_row_with_value(context, n: int, rs_id: str, q_id: str, val: str):
    rows = [a for a in context.sut.answers if a.response_set_id == rs_id and a.question_id == q_id]
    assert len(rows) == n, f"Expected {n} rows, got {len(rows)}"
    assert rows[0].value == val, f"Expected value {val}, got {rows[0].value}"


@then('the database should still contain exactly {n:d} row in "answer" for (response_set_id="{rs_id}", question_id="{q_id}")')
@then('the database should still contain exactly {n:d} row in "answer" for (response\\_set\\_id="{rs_id}", question\\_id="{q_id}")')
def step_then_still_exact_row(context, n: int, rs_id: str, q_id: str):
    rows = [a for a in context.sut.answers if a.response_set_id == rs_id and a.question_id == q_id]
    assert len(rows) == n, f"Expected {n} rows, got {len(rows)}"


@then('the database should not create or update any row in "answer" for (response_set_id="{rs_id}", question_id="{q_id}")')
@then('the database should not create or update any row in "answer" for (response\\_set\\_id="{rs_id}", question\\_id="{q_id}")')
def step_then_no_row_created(context, rs_id: str, q_id: str):
    rows = [a for a in context.sut.answers if a.response_set_id == rs_id and a.question_id == q_id]
    assert len(rows) == 0, f"Expected 0 rows, got {len(rows)}"


@then('the database value in "answer" for (response_set_id="{rs_id}", question_id="{q_id}") should still equal "{val}"')
@then('the database value in "answer" for (response\\_set\\_id="{rs_id}", question\\_id="{q_id}") should still equal "{val}"')
def step_then_value_unchanged(context, rs_id: str, q_id: str, val: str):
    rows = [a for a in context.sut.answers if a.response_set_id == rs_id and a.question_id == q_id]
    assert len(rows) == 1, f"Expected 1 row, got {len(rows)}"
    assert rows[0].value == val, f"Expected value {val}, got {rows[0].value}"


@then('the database table "question" should include a row where external_qid="{ext}" and answer_kind="{ak}"')
@then('the database table "question" should include a row where external\_qid="{ext}" and answer\_kind="{ak}"')
def step_then_question_row_exists(context, ext: str, ak: str):
    qid = context.sut.questions_by_external.get(ext)
    assert qid, f"No question with external_qid={ext}"
    q = context.sut.questions[qid]
    assert q.answer_kind == ak, f"Expected answer_kind={ak}, got {q.answer_kind}"


@then('the database table "answer\\_option" should include {n:d} rows for the new question ordered by sort\\_index')
def step_then_answer_options(context, n: int):
    # Find the most recently created question (best-effort: last by creation in this mock is not tracked; instead use ext id used in import scenario)
    qid = context.sut.questions_by_external.get("Q_FAV_FRUIT")
    assert qid, "Expected imported question Q_FAV_FRUIT to exist"
    opts = [o for o in context.sut.answer_options if o.question_id == qid]
    opts_sorted = sorted(opts, key=lambda o: o.sort_index)
    assert len(opts_sorted) == n, f"Expected {n} options, got {len(opts_sorted)}"
    # Ensure order is by sort_index
    assert [o.sort_index for o in opts_sorted] == list(range(1, n + 1))


@then('the first line of the CSV equals "{expected}"')
def step_then_first_csv_line(context, expected: str):
    text = context.last_response["text"]
    assert isinstance(text, str), "Expected CSV text response"
    first_line = text.splitlines()[0]
    # Unescape feature-escaped underscores in expected header
    expected = expected.replace('\\_', '_')
    assert first_line == expected


@then("subsequent rows are ordered by screen\\_key asc, question\\_order asc, then question\\_id asc")
def step_then_csv_sorted(context):
    text = context.last_response["text"]
    lines = text.splitlines()
    rows = list(csv.reader(io.StringIO("\n".join(lines[1:]))))
    # Extract fields by defined header order
    def key(row: List[str]) -> Tuple[str, int, str]:
        screen_key = row[1]
        try:
            question_order = int(row[2])
        except Exception:
            question_order = 0
        # Derive the third sort key deterministically using external_qid -> question_id mapping
        external_qid = row[0]
        qid = context.sut.questions_by_external.get(external_qid, "")
        return (screen_key, question_order, qid)
    expected_sorted = sorted(rows, key=key)
    if rows != expected_sorted:
        header_row = lines[0] if lines else ""
        keys = [key(r) for r in rows]
        # Find first violation position
        bad_positions: List[int] = []
        for i, (r_actual, r_expected) in enumerate(zip(rows, expected_sorted)):
            if r_actual != r_expected:
                bad_positions.append(i)
        print("DEBUG csv_sorted: header=", header_row)
        print("DEBUG csv_sorted: computed_keys=", keys)
        if bad_positions:
            print("DEBUG csv_sorted: first_mismatch_index=", bad_positions[0])
            print("DEBUG csv_sorted: row_at_index=", rows[bad_positions[0]])
            print("DEBUG csv_sorted: expected_row_at_index=", expected_sorted[bad_positions[0]])
            # Persist structured mismatch details for CI parsing
            _append_failure_jsonl(
                context,
                {
                    "step": "ordering_check",
                    "first_mismatch_index": bad_positions[0],
                    "row_at_index": rows[bad_positions[0]],
                    "expected_row_at_index": expected_sorted[bad_positions[0]],
                },
            )
        raise AssertionError("CSV rows are not in expected order")


@then('the database table "question" should not contain any row where external_qid="{ext}"')
@then('the database table "question" should not contain any row where external\_qid="{ext}"')
def step_then_question_row_not_exists(context, ext: str):
    assert ext not in context.sut.questions_by_external, f"Found unexpected question with external_qid={ext}"
